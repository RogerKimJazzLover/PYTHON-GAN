{"cells":[{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":1987,"status":"ok","timestamp":1723027035229,"user":{"displayName":"김민승","userId":"07009041031692465503"},"user_tz":-540},"id":"CgNNZE4fyZ_1"},"outputs":[],"source":["import torch\n","import torchvision\n","from torch import nn\n","\n","# For train dataset\n","from torchvision.datasets import MNIST\n","from torchvision import transforms\n","\n","import matplotlib.pyplot as plt\n","from tqdm import tqdm"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"executionInfo":{"elapsed":15750,"status":"ok","timestamp":1723027053831,"user":{"displayName":"김민승","userId":"07009041031692465503"},"user_tz":-540},"id":"5aL3cRGozxj8","outputId":"d0b51630-2f11-44e6-c4dc-db138f63e849"},"outputs":[],"source":["# Make Train Data\n","transform = transforms.Compose([\n","    transforms.ToTensor(),\n","    transforms.Normalize((0.5,), (0.5,))\n","])\n","\n","train_dataset = MNIST(root='./data', train=True, transform=transform, download=True)\n","train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=64, shuffle=True)"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":583,"status":"ok","timestamp":1723027057003,"user":{"displayName":"김민승","userId":"07009041031692465503"},"user_tz":-540},"id":"t_uRhoS1z5zC"},"outputs":[],"source":["latent_dim = 100\n","class Generator(nn.Module):\n","  def __init__(self):\n","    super(Generator, self).__init__()\n","\n","    # Define the Generator's architecture\n","    self.model = nn.Sequential(\n","        nn.Linear(latent_dim, 256),\n","        nn.LeakyReLU(0.2),\n","        nn.Linear(256, 512),\n","        nn.LeakyReLU(0.2),\n","        nn.Linear(512, 1024),\n","        nn.LeakyReLU(0.2),\n","        nn.Linear(1024, 28*28),\n","        nn.Tanh()\n","    )\n","\n","  def forward(self, x):\n","    return self.model(x)"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":491,"status":"ok","timestamp":1723027060579,"user":{"displayName":"김민승","userId":"07009041031692465503"},"user_tz":-540},"id":"mH0JxW0D0A-c"},"outputs":[],"source":["class Discriminator(nn.Module):\n","  def __init__(self):\n","    super(Discriminator, self).__init__()\n","    # Define the Discriminator's architecture\n","    self.model = nn.Sequential(\n","      nn.Linear(28*28, 1024),\n","      nn.LeakyReLU(0.2),\n","      nn.Dropout(0.3),\n","      nn.Linear(1024, 512),\n","      nn.LeakyReLU(0.2),\n","      nn.Dropout(0.3),\n","      nn.Linear(512, 256),\n","      nn.LeakyReLU(0.2),\n","      nn.Dropout(0.3),\n","      nn.Linear(256, 1),\n","      nn.Sigmoid()\n","    )\n","\n","  def forward(self, x):\n","    return self.model(x)"]},{"cell_type":"code","execution_count":10,"metadata":{"executionInfo":{"elapsed":626,"status":"ok","timestamp":1723027381371,"user":{"displayName":"김민승","userId":"07009041031692465503"},"user_tz":-540},"id":"kLzEet-Z0Ei_"},"outputs":[],"source":["# Loss function\n","criterion = nn.BCELoss()\n","\n","generator = Generator()\n","discriminator = Discriminator()\n","\n","lr = 0.00021\n","\n","# Optimizers\n","G_optimizer = torch.optim.Adam(generator.model.parameters(), lr=lr, betas=(0.5, 0.999))\n","D_optimizer = torch.optim.Adam(discriminator.model.parameters(), lr=lr, betas=(0.5, 0.999))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"executionInfo":{"elapsed":466192,"status":"ok","timestamp":1723027866306,"user":{"displayName":"김민승","userId":"07009041031692465503"},"user_tz":-540},"id":"2c_1liQN0HUS","outputId":"a06970e9-f113-4c9a-cfe2-6929e10618a5"},"outputs":[],"source":["import torch.autograd as autograd\n","\n","num_epochs = 30\n","# Tries to use GPU\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","generator.to(device)\n","discriminator.to(device)\n","criterion.to(device)\n","\n","# Training loop\n","for epoch in range(num_epochs):\n","    for i, (images, _) in enumerate(train_loader):\n","        # Flatten the images for the Discriminator\n","        images = images.view(images.size(0), -1).to(device)\n","\n","        # Real labels are 1, fake labels are 0\n","        real_labels = torch.ones(images.size(0), 1).to(device)\n","        fake_labels = torch.zeros(images.size(0), 1).to(device)\n","\n","        ############################\n","        # Train the Discriminator\n","        ############################\n","        D_optimizer.zero_grad()\n","\n","        # Compute BCELoss using real images\n","        outputs = discriminator(images)\n","        D_loss_real = criterion(outputs, real_labels)\n","        real_score = outputs\n","\n","        # Generate fake images\n","        z = torch.randn(images.size(0), latent_dim).to(device)\n","        fake_images = generator(z)\n","\n","        # Compute BCELoss using fake images\n","        outputs = discriminator(fake_images.detach())\n","        D_loss_fake = criterion(outputs, fake_labels)\n","        fake_score = outputs\n","\n","        # Optimize the Discriminator\n","        D_loss = D_loss_real + D_loss_fake\n","        D_loss.backward()\n","        D_optimizer.step()\n","\n","        ############################\n","        # Train the Generator\n","        ############################\n","        G_optimizer.zero_grad()\n","\n","        # Generate fake images\n","        z = torch.randn(images.size(0), latent_dim).to(device)\n","        fake_images = generator(z)\n","\n","        # Compute BCELoss using fake images, with reversed labels\n","        outputs = discriminator(fake_images)\n","        G_loss = criterion(outputs, real_labels)\n","\n","        # Optimize the Generator\n","        G_loss.backward()\n","        G_optimizer.step()\n","\n","        if (i+1) % 100 == 0:\n","            print('Epoch [{}/{}], Step [{}/{}], D_loss: {:.4f}, G_loss: {:.4f}, D(x): {:.2f}, D(G(z)): {:.2f}'\n","                  .format(epoch+1, num_epochs, i+1, len(train_loader), D_loss.item(), G_loss.item(),\n","                          real_score.mean().item(), fake_score.mean().item()))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":98},"executionInfo":{"elapsed":1948,"status":"ok","timestamp":1723028140245,"user":{"displayName":"김민승","userId":"07009041031692465503"},"user_tz":-540},"id":"OAtNGXOJ0H69","outputId":"fdf8678e-a0a8-4475-b42e-a1ae0d5518de"},"outputs":[],"source":["# Generate fake images for visualization\n","z = torch.randn(16, latent_dim).to(device)\n","fake_images = generator(z)\n","fake_images = fake_images.view(fake_images.size(0), 1, 28, 28)\n","fake_images = (fake_images + 1) / 2  # Rescale images to [0, 1]\n","\n","# Plot the fake images\n","import matplotlib.pyplot as plt\n","\n","fig, axes = plt.subplots(1, 16, figsize=(15, 15))\n","for ax, img in zip(axes.flatten(), fake_images):\n","    ax.axis('off')\n","    ax.set_adjustable('box')\n","    img = transforms.ToPILImage()(img.cpu().squeeze())\n","    ax.imshow(img, cmap='gray')\n","plt.show()"]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyODGEk8sdrD53ykvjkr/EUP","gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
